for my training loop, I have the following code:

it is in between

loss = self.criterion(output, target) # Apply CrossEntropyLoss directly to the logits

it goes here before
                if self.adversarial:

# # supervised algorithm
                # if self.model_name == 'SVM':
                #     # Use SupervisedLearning class for LogisticRegression
                #     model = getattr(self.supervised_learning, self.model_name.lower() + '_classifier')
                #     trained_model = model(data.cpu().numpy(), target.cpu().numpy())
                #     output = trained_model.predict(data.cpu().numpy())
                #     loss = self.criterion(torch.tensor(output), target)

                # elif self.model_name == 'SVM':
                #     # Use SupervisedLearning class for SVM
                #     model = getattr(self.supervised_learning, self.model_name.lower() + '_classifier')
                #     trained_model = model(data.cpu().numpy(), target.cpu().numpy())
                #     output = trained_model.predict(data.cpu().numpy())
                #     loss = self.criterion(torch.tensor(output), target)
                # if self.model_name in [
                #                          # 'RandomForest',
                #                          'GradientBoosting',
                #                          # 'AdaBoost', # decrease
                #                          # 'XGBoost',
                #                          # 'LightGBM'
                #                          ]:
                #     # Instantiate and train other models directly
                #     model = getattr(self.supervised_learning, self.model_name.lower() + '_classifier')
                #     trained_model = model(data.cpu().numpy(), target.cpu().numpy())
                #     output = trained_model.predict(data.cpu().numpy())
                #     loss = self.criterion(torch.tensor(output), target)
                # else:
                #     output = self.model(data)
                #     # output = torch.sigmoid(output)
                #     # output = torch.relu(output)
                #     loss = self.criterion(output, target)



for my taskhandler

# def run_train(self):
    #     """Runs the evaluation process for all datasets and pre-trained models."""
    #     self.current_task = 'normal_training'
    #     logging.info("Evaluation task selected.")
    #     all_results = []
    #
    #     for dataset_name, dataset_loader in self.datasets_dict.items():
    #         logging.info(f"Processing dataset: {dataset_name}")
    #         _, val_dataset, test_dataset = dataset_loader.load()  # Only loading validation and test sets
    #         input_channels = self.input_channels_dict.get(dataset_name)
    #         logging.info(f"Input channels for {dataset_name}: {input_channels}")
    #
    #         model_list = []
    #         model_names_list = []
    #         true_labels_dict = {}
    #         predictions_dict = {}
    #
    #         evaluator = None
    #         for model_name in self.models_loader.models_dict.keys():
    #             logging.info(f"Loading pre-trained model: {model_name}")
    #             model = self.models_loader.load_pretrained_model(model_name, 'normal_training', dataset_name)
    #
    #             model_list.append(model)
    #             model_names_list.append(model_name)
    #
    #             # Use the pre-trained model to create the trainer
    #             trainer = Trainer(
    #                 model=model,
    #                 train_loader=None,
    #                 val_loader=None,
    #                 test_loader=torch.utils.data.DataLoader(test_dataset,
    #                                                         batch_size=self.hyperparams_dict[dataset_name][
    #                                                             'batch_size'], shuffle=False),
    #                 optimizer=None,
    #                 criterion=self.criterion,
    #                 model_name=model_name,
    #                 task_name=self.current_task,
    #                 dataset_name=dataset_name,
    #                 device=self.device
    #             )
    #
    #             true_labels, predictions = trainer.get_test_results()
    #             true_labels_dict[model_name] = true_labels
    #             predictions_dict[model_name] = predictions
    #
    #             evaluator = Evaluator(model_name, [], true_labels, predictions, self.current_task)
    #             evaluator.evaluate(dataset_name)
    #             all_results.append(evaluator)
    #
    #         if evaluator is not None:
    #             all_results.extend(evaluator.results)
